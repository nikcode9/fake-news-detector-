{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3f7163b",
   "metadata": {},
   "source": [
    "# FAKE NEWS DETECTOR\n",
    "### Fake News Detector using Logistic Regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238668e0",
   "metadata": {},
   "source": [
    "google collab link: https://colab.research.google.com/drive/1YxD2SRlRn9YfG5Lak7Pr9b8Y7bg6maOZ?authuser=0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950fada4",
   "metadata": {},
   "source": [
    "< importing datasets directly from kaggle >\n",
    "\n",
    "dataset link: https://www.kaggle.com/competitions/fake-news/data\n",
    "\n",
    "!pip install kaggle <br>\n",
    "!kaggle competitions download -c fake-news <br>\n",
    "!unzip fake-news.zip <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7852007d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59401866",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading stopwords: <urlopen error [WinError 10061]\n",
      "[nltk_data]     No connection could be made because the target machine\n",
      "[nltk_data]     actively refused it>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bddd7da",
   "metadata": {},
   "source": [
    "In Machine Learning, stopwords are common words that are filtered out and excluded from the text processing pipeline during natural language processing (NLP) tasks. These words are typically very frequent and contribute little to the overall meaning of a document or sentence. Removing stopwords is a preprocessing step aimed at reducing the dimensionality of the text data and improving the efficiency and quality of NLP algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c476678d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aaf9073",
   "metadata": {},
   "source": [
    "< Pre-Processing the Data >\n",
    "\n",
    "Importing the dataset into a dataframe, and handling missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040202d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_dataset = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba55018c",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_dataset.head()\n",
    "news_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8818ce4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the number of missing values in the dataset\n",
    "news_dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75cfe41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing the null values with empty string\n",
    "news_dataset = news_dataset.fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195f8d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging the author name and news title\n",
    "news_dataset['content'] = news_dataset['author']+' '+news_dataset['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda24e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(news_dataset['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f24761a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separating the data & label\n",
    "X = news_dataset.drop(columns='label', axis=1)\n",
    "Y = news_dataset['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56f7fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0540e4bd",
   "metadata": {},
   "source": [
    "< Stemming Process >\n",
    "\n",
    "Stemming is a natural language processing (NLP) technique used in Machine Learning to reduce words to their root or base form, called the \"stem.\" The purpose of stemming is to normalize words with the same root, even if they have different endings or suffixes, so that they can be treated as the same word during text processing and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79960320",
   "metadata": {},
   "outputs": [],
   "source": [
    "port_stem = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804633b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemming(content):\n",
    "    stemmed_content = re.sub('[^a-zA-Z]',' ',content)\n",
    "    stemmed_content = stemmed_content.lower()\n",
    "    stemmed_content = stemmed_content.split()\n",
    "    stemmed_content = [port_stem.stem(word) for word in stemmed_content if not word in stopwords.words('english')]\n",
    "    stemmed_content = ' '.join(stemmed_content)\n",
    "    return stemmed_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6294cd27",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_dataset['content'] = news_dataset['content'].apply(stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a054bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(news_dataset['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ef1ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#separating the data and label\n",
    "X = news_dataset['content'].values\n",
    "Y = news_dataset['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86238c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X)\n",
    "X.shape\n",
    "print(Y)\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b6752d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting the textual data to numerical data\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit(X)\n",
    "\n",
    "X = vectorizer.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a09f5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e9d7ea",
   "metadata": {},
   "source": [
    "< Splitting training and testing data >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad99aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, stratify=Y, random_state=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d77b392",
   "metadata": {},
   "source": [
    "< Training the model >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809c0625",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdeb455",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4cd6762",
   "metadata": {},
   "source": [
    "< Model Accuracy >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b131166c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy score on the training data\n",
    "X_train_prediction = model.predict(X_train)\n",
    "training_data_accuracy = accuracy_score(X_train_prediction, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97de3e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy of Training data : ', training_data_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e5f7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy score on the testing data\n",
    "X_test_prediction = model.predict(X_test)\n",
    "test_data_accuracy = accuracy_score(X_test_prediction, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e3fdcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy of Test data : ', test_data_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3972991",
   "metadata": {},
   "source": [
    "< Prediction >\n",
    "\n",
    "0 = Real News <br>\n",
    "1 = Fake News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af519b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = X_test[3]\n",
    "\n",
    "prediction = model.predict(X_new)\n",
    "print(prediction)\n",
    "\n",
    "if (prediction[0]==0):\n",
    "  print('The news is Real')\n",
    "else:\n",
    "  print('The news is Fake')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fd4af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = Y_test[3]\n",
    "\n",
    "if (res == 0)\n",
    "    print('The news is Real - 0')\n",
    "else\n",
    "    print('The news is Fake - 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3753dafc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
